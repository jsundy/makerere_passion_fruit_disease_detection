{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE_DIR = \"Data/Train_Images\"\n",
    "IMAGE_DIR = \"Data/Batch\"\n",
    "DATA = \"Data/Train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_data_set_to_df(data, image_data):\n",
    "    transormed_data = []\n",
    "    for image_filename in image_data:\n",
    "        image_id = image_filename.replace(\".jpg\", \"\")\n",
    "        dataframes = data.loc[data[\"Image_ID\"] == image_id]\n",
    "        for index, df in dataframes.iterrows():\n",
    "            transormed_data.append([\n",
    "                df[\"Image_ID\"],\n",
    "                df[\"class\"],\n",
    "                df[\"xmin\"],\n",
    "                df[\"ymin\"],\n",
    "                df[\"xmin\"] + df[\"width\"],\n",
    "                df[\"ymin\"] + df[\"height\"]\n",
    "            ])\n",
    "    transormed_df = pd.DataFrame(data=transormed_data, columns=['img_id', 'names', 'xmin', 'ymin', 'xmax', 'ymax'])\n",
    "    return transormed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA)\n",
    "train_image_filenames = os.listdir(IMAGE_DIR)\n",
    "\n",
    "df = image_data_set_to_df(data=data, image_data=train_image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['names'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = preprocessing.LabelEncoder()\n",
    "df['labels'] = enc.fit_transform(df['names'])\n",
    "df['labels'] = np.stack(df['labels'][i]+1 for i in range(len(df['labels']))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = df[['names','labels']].value_counts()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes= {\n",
    "    1:'fruit_brownspot',\n",
    "    2:'fruit_healthy',\n",
    "    3:'fruit_woodiness'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "class PassionFruitDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, image_dir, transforms=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.image_ids = dataframe['img_id'].unique()\n",
    "        self.df = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        image_id = self.image_ids[index]\n",
    "        records = self.df[self.df['img_id'] == image_id]\n",
    "        \n",
    "        image = cv2.imread(f'{self.image_dir}/{image_id}.jpg', cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "        rows, cols = image.shape[:2]\n",
    "        \n",
    "        boxes = records[['xmin', 'ymin', 'xmax', 'ymax']].values\n",
    "        \n",
    "       \n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        area = torch.as_tensor(area, dtype=torch.float32)\n",
    "        \n",
    "        label = records['labels'].values\n",
    "        labels = torch.as_tensor(label, dtype=torch.int64)\n",
    "        \n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((records.shape[0],), dtype=torch.int64)\n",
    "        \n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "        # target['masks'] = None\n",
    "        target['image_id'] = torch.tensor([index])\n",
    "        target['area'] = area\n",
    "        target['iscrowd'] = iscrowd\n",
    "        \n",
    "        if self.transforms:\n",
    "            sample = {\n",
    "                'image': image,\n",
    "                'bboxes': target['boxes'],\n",
    "                'labels': labels\n",
    "            }\n",
    "            sample = self.transforms(**sample)\n",
    "            image = sample['image']\n",
    "            \n",
    "            target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1,0)\n",
    "            \n",
    "            return image, target\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return self.image_ids.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform_train():\n",
    "    return A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.2),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format':'pascal_voc', 'label_fields': ['labels']})\n",
    "\n",
    "def get_transform_valid():\n",
    "    return A.Compose([\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields':['labels']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PassionFruitDataset(train_df, IMAGE_DIR , get_transform_train())\n",
    "valid_dataset = PassionFruitDataset(valid_df, IMAGE_DIR, get_transform_valid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset in train and test set\n",
    "indices = torch.randperm(len(train_dataset)).tolist()\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "valid_data_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets= next(iter(train_data_loader))\n",
    "images = list(image.to(device) for image in images)\n",
    "targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "for i, (image, target) in enumerate(zip(images, targets)):\n",
    "    plt.subplot(2,2, i+1)\n",
    "    boxes = targets[i]['boxes'].cpu().numpy().astype(np.int32)\n",
    "    sample = images[i].permute(1,2,0).cpu().numpy()\n",
    "    names = targets[i]['labels'].cpu().numpy().astype(np.int64)\n",
    "    for i,box in enumerate(boxes):\n",
    "        cv2.rectangle(sample,\n",
    "                      (box[0], box[1]),\n",
    "                      (box[2], box[3]),\n",
    "                      (0, 0, 220), 2)\n",
    "        cv2.putText(sample, classes[names[i]], (box[0],box[1]+15),cv2.FONT_HERSHEY_COMPLEX ,0.5,(0,220,0),1,cv2.LINE_AA)  \n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.imshow(sample)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a model; pre-trained on COCO\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "\n",
    "# get number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, weight_decay=0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/pytorch/vision.git\n",
    "# !cd vision;cp references/detection/utils.py ../;cp references/detection/transforms.py ../;cp references/detection/coco_eval.py ../;cp references/detection/engine.py ../;cp references/detection/coco_utils.py ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _summarize(p, s, ap=1, iouThr=None, areaRng='all', maxDets=100):\n",
    "    # p = self.params\n",
    "    iStr = ' {:<18} {} @[ IoU={:<9} | area={:>6s} | maxDets={:>3d} ] = {:0.3f}'\n",
    "    titleStr = 'Average Precision' if ap == 1 else 'Average Recall'\n",
    "    typeStr = '(AP)' if ap==1 else '(AR)'\n",
    "    iouStr = '{:0.2f}:{:0.2f}'.format(p.iouThrs[0], p.iouThrs[-1]) \\\n",
    "        if iouThr is None else '{:0.2f}'.format(iouThr)\n",
    "\n",
    "    aind = [i for i, aRng in enumerate(p.areaRngLbl) if aRng == areaRng]\n",
    "    mind = [i for i, mDet in enumerate(p.maxDets) if mDet == maxDets]\n",
    "    if ap == 1:\n",
    "        # dimension of precision: [TxRxKxAxM]\n",
    "        # IoU\n",
    "        if iouThr is not None:\n",
    "            t = np.where(iouThr == p.iouThrs)[0]\n",
    "            s = s[t]\n",
    "        s = s[:,:,:,aind,mind]\n",
    "    else:\n",
    "        # dimension of recall: [TxKxAxM]\n",
    "        if iouThr is not None:\n",
    "            t = np.where(iouThr == p.iouThrs)[0]\n",
    "            s = s[t]\n",
    "        s = s[:,:,aind,mind]\n",
    "    if len(s[s>-1])==0:\n",
    "        mean_s = -1\n",
    "    else:\n",
    "        mean_s = np.mean(s[s>-1])\n",
    "    print(iStr.format(titleStr, typeStr, iouStr, areaRng, maxDets, mean_s))\n",
    "    return mean_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_default = {         \n",
    "    \"batch_size\": 8,          # input batch size for training (default: 64)\n",
    "    \"test_batch_size\": 8,    # input batch size for testing (default: 1000)\n",
    "    \"epochs\": 2,             # number of epochs to train (default: 10)\n",
    "    \"lr\": 0.005,               # learning rate (default: 0.01)\n",
    "    \"momentum\": 0.9,          # SGD momentum (default: 0.5) \n",
    "    \"no_cuda\": False,         # whether to disable CUDA training\n",
    "    \"seed\": 42,               # random seed (default: 42)\n",
    "    \"log_interval\": 1,      #how many batches to wait before logging in train/test loops\n",
    "    \"image_log_interval\": 10,\n",
    "    \"decay\": 0.0005\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision_and_recall_metrics(coco_evaluator):\n",
    "    data = {}\n",
    "    coco = coco_evaluator.coco_eval['bbox']\n",
    "    data['metrics/mAP_0.5'] = _summarize(coco.params, coco.eval['precision'], 1, iouThr=.5, maxDets=coco.params.maxDets[2])\n",
    "    data['metrics/mAP_0.5:0.95'] = _summarize(coco.params, coco.eval['precision'], 1, areaRng='large', maxDets=coco.params.maxDets[2])\n",
    "    data[\"metrics/recall\"] = _summarize(coco.params, coco.eval['recall'], 0, iouThr=.5, maxDets=coco.params.maxDets[1])\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_data(metric_logger):\n",
    "    d = {}\n",
    "    data = {}\n",
    "    for metric in metric_logger.meters.items():\n",
    "        d[metric[0]] = metric[1].avg\n",
    "    \n",
    "    data['train/obj_loss'] = d['loss_objectness']\n",
    "    data['train/box_loss'] = d['loss_box_reg']\n",
    "    data['train/cls_loss'] = d['loss_classifier']\n",
    "    data['loss'] = d['loss']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(config=config_default, project=\"GWD-fasterRCNN\", api_key=\"dbfbcbefbdb1ccbef7d90bf547b9a11b9a696bd1\")\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(config=config_default, project=\"GWD-fasterRCNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's train it for 2 epochs\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    wand_data = {}\n",
    "    # train for one epoch, printing every 10 iterations\n",
    "    metric_logger = train_one_epoch(model, optimizer, train_data_loader, device, epoch, print_freq=10)\n",
    "    metric_data = get_loss_data(metric_logger)\n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    # evaluate on the test dataset\n",
    "    coco_evaluator = evaluate(model, valid_data_loader, device=device)\n",
    "    metric_data.update(get_precision_and_recall_metrics(coco_evaluator))\n",
    "    wandb.log(metric_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_evaluator.analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'faster_rcnn_state.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "all_precision =  evaluator.eval['precision']\n",
    "all_precision =  evaluator.eval['precision']\n",
    "\n",
    "pr_5 = all_precision[0, :, 0, 0, 2] # data for IoU@0.5\n",
    "pr_7 = all_precision[4, :, 0, 0, 2] # data for IoU@0.7\n",
    "pr_9 = all_precision[8, :, 0, 0, 2] # data for IoU@0.9\n",
    "\n",
    "x = np.arange(0, 1.01, 0.01)\n",
    "plt.plot(x, pr_5, label='IoU@0.5')\n",
    "plt.plot(x, pr_7, label='IoU@0.7')\n",
    "plt.plot(x, pr_9, label='IoU@0.9')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load  a model; pre-trained on COCO\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False, pretrained_backbone=False)\n",
    "\n",
    "WEIGHTS_FILE = \"./faster_rcnn_state.pth\"\n",
    "\n",
    "num_classes = 4\n",
    "\n",
    "# get number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "# Load the traines weights\n",
    "model.load_state_dict(torch.load(WEIGHTS_FILE))\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_detector(img):\n",
    "    img = cv2.imread(img, cv2.IMREAD_COLOR)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "    img /= 255.0\n",
    "    img = torch.from_numpy(img)\n",
    "    img = img.unsqueeze(0)\n",
    "    img = img.permute(0,3,1,2)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    detection_threshold = 0.70\n",
    "    \n",
    "    img = list(im.to(device) for im in img)\n",
    "    output = model(img)\n",
    "\n",
    "    for i , im in enumerate(img):\n",
    "        boxes = output[i]['boxes'].data.cpu().numpy()\n",
    "        scores = output[i]['scores'].data.cpu().numpy()\n",
    "        labels = output[i]['labels'].data.cpu().numpy()\n",
    "\n",
    "        labels = labels[scores >= detection_threshold]\n",
    "        boxes = boxes[scores >= detection_threshold].astype(np.int32)\n",
    "        scores = scores[scores >= detection_threshold]\n",
    "\n",
    "        boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n",
    "        boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n",
    "    \n",
    "    sample = img[0].permute(1,2,0).cpu().numpy()\n",
    "    sample = np.array(sample)\n",
    "    boxes = output[0]['boxes'].data.cpu().numpy()\n",
    "    name = output[0]['labels'].data.cpu().numpy()\n",
    "    scores = output[0]['scores'].data.cpu().numpy()\n",
    "    boxes = boxes[scores >= detection_threshold].astype(np.int32)\n",
    "    names = name.tolist()\n",
    "    \n",
    "    return names, boxes, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path = \"Data/Batch\"\n",
    "pred_files = [os.path.join(pred_path,f) for f in os.listdir(pred_path)]\n",
    "\n",
    "plt.figure(figsize=(20,60))\n",
    "for i, images in enumerate(pred_files):\n",
    "    if i > 19:break\n",
    "    plt.subplot(10,2,i+1)\n",
    "    names,boxes,sample = obj_detector(images)\n",
    "    for i,box in enumerate(boxes):\n",
    "        cv2.rectangle(sample,\n",
    "                      (box[0], box[1]),\n",
    "                      (box[2], box[3]),\n",
    "                      (0, 220, 0), 2)\n",
    "        cv2.putText(sample, classes[names[i]], (box[0],box[1]-5),cv2.FONT_HERSHEY_COMPLEX ,0.7,(220,0,0),1,cv2.LINE_AA)  \n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.imshow(sample)\n",
    "#     plt.savefig('save_image.png', bbox_inches='tight')  # if you want to save result"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f2a57deb879eeb0415da9a85fcba1c7434c135399e40604c63c8cd18fdf340b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('makerere-Kyu4rfJJ-py3.8': poetry)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
